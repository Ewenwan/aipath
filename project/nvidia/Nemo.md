# Nemo

## 使用 NeMo 训练中英双语 TTS 语音合成模型

NVIDIA NeMo 是一个用于构建对话式人工智能应用的工具库，专为从事自动语音识别 (ASR)、语音合成 (TTS)、大型语言模型 (LLM) 和自然语言处理 (NLP) 工作的研究人员打造。NeMo 的主要目标是帮助工业界和学术界的研究人员重用之前的工作（代码和预训练模型），让创建新的对话式 AI 模型使用起来更加容易。助力研发人员构建人机交互的对话式解决方案，搭建智能语音助手，聊天机器人，智能语音翻译等对话式AI应用场景。

在 TTS 语音合成部分，文字当中出现中文夹杂英文的使用场景和语音合成需求变得越来越多，因此我们可以使用 NVIDIA 完全并行的语音合成模型 FastPitch 和高效的声码器 HiFi-GAN 来合成更高质量的中英夹杂的语音内容。

本次网络研讨会主要面向有 NLP 和对话式 AI 开发需求的开发者。通过本次网络研讨会，您可以获得以下信息：

* NVIDIA NeMo 介绍
* Fastpitch 和 HiFi-GAN 模型架构
* 使用预训练模型进行推理
* SF 中英双语数据集介绍
* Fastpitch 模型的训练与评估

## Transducer 模型在自动语音识别中的应用 – NVIDIA NeMo 代码解析

在 ASR 自动语音识别领域，基于 CTC 的声学模型不再需要对训练的音频序列和文本序列进行强制对齐，实际上已经初步具备了端到端的声学模型建模能力。但是 CTC 模型进行声学建模存在着两个严重的瓶颈，一是缺乏语言模型建模能力，不能整合语言模型进行联合优化，二是 CTC 有一个不合理的假设：标签相互独立，这个基本假设与语音识别任务之间存在着一定程度的背离，因为在语言系统中存在语境的上下文关系。因此针对 CTC 的不足，Transducer模型可以弥补这种不合理的假设，解决 CTC 的问题。在本次分享中我们将重点讨论 Transducer 模型，并通过代码来训练和评估Transducer模型。

通过本次网络研讨会，您可以获得以下信息：

* Transducer 介绍
* Transducer loss 的优势和局限
* Transducer 的模型架构
* ContextNet 的模型架构
* Transducer 模型的训练和评估
